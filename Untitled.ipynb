{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cde010a-2b60-4a1b-8e7d-e6d124548240",
   "metadata": {},
   "source": [
    "# Project 4: Sentiment Analysis of Text\n",
    "\n",
    "This project involves building and evaluating deep learning models (RNNs or Transformers) for sentiment classification of text, such as movie reviews or product feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661f799-04cc-477d-a497-4267ff78d464",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f43da2d-8a7f-4a5e-bb61-ef186639d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e848d9e3-fc5a-47ff-b29c-037a079cb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Python & Data Handling\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# PyTorch Core\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "# For Reproducibility (optional but recommended)\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# for progress bars\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "774877db-1d9a-4a1e-99fb-c0420aca9bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79038126-4c30-4196-ba85-82ee0f67ce48",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac4e2cb1-a156-43d9-9b6c-8a13e216b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "196c1cf7-c36d-49be-b168-204b1241eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69d98439-c7ac-45fd-8fc1-b74c047042c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(path: str, label: str, text: str, delimiter= \",\"):\n",
    "    df = pd.read_csv(path,delimiter=delimiter)\n",
    "\n",
    "    df = df.rename(columns={text: \"text\", label: \"label\"})\n",
    "\n",
    "    if not df['label'].isin([0, 1, -1]).all():\n",
    "        df['label'] = df['label'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "    num_labels = df['label'].nunique()\n",
    "    print(f\"Number of distinct labels: {num_labels}\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(f\"Number of rows: {df.shape[0]}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866fd423-fee5-45d3-b413-abe4b2e47180",
   "metadata": {},
   "source": [
    "## IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35d20b5c-1361-42d1-99f1-8e2a6f01e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n"
     ]
    }
   ],
   "source": [
    "dataset = 'lakshmi25npathi/imdb-dataset-of-50k-movie-reviews'\n",
    "api.dataset_download_files(dataset, path= 'IMDB', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3144023-ebb1-4fca-9693-d16ca68d2de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct labels: 2\n",
      "                                                text  label\n",
      "0  One of the other reviewers has mentioned that ...      1\n",
      "1  A wonderful little production. <br /><br />The...      1\n",
      "2  I thought this was a wonderful way to spend ti...      1\n",
      "3  Basically there's a family where a little boy ...      0\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...      1\n",
      "Number of rows: 50000\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(\"IMDB\", \"IMDB Dataset.csv\")\n",
    "imdb = show_data(path, \"sentiment\", \"review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9adc7-b04c-4f0e-ae45-58ea584ea0fb",
   "metadata": {},
   "source": [
    "## SST-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4d87da9-537a-469a-b325-ebbeb897b1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/jkhanbk1/sst2-dataset\n"
     ]
    }
   ],
   "source": [
    "dataset = 'jkhanbk1/sst2-dataset'\n",
    "api.dataset_download_files(dataset, path='.', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "349e92b9-3b1f-47d2-914d-82deb2d7678b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct labels: 2\n",
      "   label                                               text\n",
      "0      0        No movement, no yuks, not much of anything.\n",
      "1      0  A gob of drivel so sickly sweet, even the eage...\n",
      "2      0  Gangs of New York is an unapologetic mess, who...\n",
      "3      0  We never really feel involved with the story, ...\n",
      "4      1              This is one of Polanski's best films.\n",
      "Number of rows: 1821\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(\"Finalv SST-2 dataset CSV format\", \"test.csv\")\n",
    "sst_2 = show_data(path, \"label\", \"sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a12905-6f2f-4b22-8863-7abd7180d155",
   "metadata": {},
   "source": [
    "## SemEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93e6676e-96d2-496b-a485-7e80247812c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/azzouza2018/semevaldatadets\n"
     ]
    }
   ],
   "source": [
    "dataset = 'azzouza2018/semevaldatadets'\n",
    "api.dataset_download_files(dataset, path='semEval', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eee26066-449d-4cda-8e45-957f3d8421eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct labels: 3\n",
      "   label                                               text\n",
      "0      0  Watching Devil Inside for the 1st time tonight...\n",
      "1      0  @CMPunk Devil Inside , The exorcisism of Emily...\n",
      "2      0  Off to do my vlog. Watching Devil Inside and J...\n",
      "3      1  @raykipo take Silver at the Hib cup. Great day...\n",
      "4      0  @hollyhippo I'm going to blockbuster tomorrow ...\n",
      "Number of rows: 1650\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(\"semEval\", \"semeval-2013-dev.csv\")\n",
    "sem_eval= show_data(path, \"label\", \"text\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c63909d-a789-4897-9a42-cb0fbabd768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53471\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53471 entries, 0 to 1649\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    53471 non-null  object\n",
      " 1   label   53471 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "frames = [imdb, sst_2, sem_eval]\n",
    "df = pd.concat(frames)\n",
    "print(df.shape[0])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d642ee4d-a8c4-49a7-bf73-0699cead72f1",
   "metadata": {},
   "source": [
    "# Text Preprocessing and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd896e75-5ab7-4320-954f-cacd61fda480",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5e17e37-9c72-45e1-b756-991a3e549a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aksinia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Aksinia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "df['tokenized_sents'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c06c5c-8448-4815-adc4-6c521ff9432a",
   "metadata": {},
   "source": [
    "Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c9fc9b6c-4098-4dca-bc75-dded9438889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "MAX_SEQ_LEN = 250\n",
    "\n",
    "counter = Counter()\n",
    "for tokens in df['tokenized_sents']:\n",
    "    counter.update(tokens)\n",
    "    \n",
    "vocab = {word: i+2 for i, (word, _) in enumerate(counter.most_common())}\n",
    "vocab['<PAD>'] = 0\n",
    "vocab['<UNK>'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d81b7e-5106-4383-9174-5126b97e04be",
   "metadata": {},
   "source": [
    "Convert Text to Sequences of Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "666cba24-cc89-47ad-90e2-e2415aa51447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_indices(tokens, vocab):\n",
    "    return [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "\n",
    "df['input_ids'] = df['tokenized_sents'].apply(lambda x: tokens_to_indices(x, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "028942c0-26ab-4730-9c98-4a834de49733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0  One of the other reviewers has mentioned that ...      2   \n",
      "1  A wonderful little production. <br /><br />The...      2   \n",
      "2  I thought this was a wonderful way to spend ti...      2   \n",
      "3  Basically there's a family where a little boy ...      1   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...      2   \n",
      "\n",
      "                                     tokenized_sents  \\\n",
      "0  [One, of, the, other, reviewers, has, mentione...   \n",
      "1  [A, wonderful, little, production, ., <, br, /...   \n",
      "2  [I, thought, this, was, a, wonderful, way, to,...   \n",
      "3  [Basically, there, 's, a, family, where, a, li...   \n",
      "4  [Petter, Mattei, 's, ``, Love, in, the, Time, ...   \n",
      "\n",
      "                                           input_ids  label_transformed  \n",
      "0  [297, 7, 2, 100, 2083, 55, 1095, 17, 143, 176,...                  2  \n",
      "1  [133, 433, 144, 389, 4, 12, 13, 10, 11, 12, 13...                  2  \n",
      "2  [15, 214, 19, 20, 6, 433, 115, 8, 1152, 72, 33...                  2  \n",
      "3  [2574, 68, 18, 6, 264, 142, 6, 144, 521, 28, 3...                  1  \n",
      "4  [94719, 11893, 18, 32, 1226, 14, 2, 2183, 7, 8...                  2  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f3de79-91ee-42b4-aa72-e9f1ceb51450",
   "metadata": {},
   "source": [
    "Add pad sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "25bd10b8-cf4f-43d0-839e-dd53e7763280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(seq):\n",
    "    if len(seq) < MAX_SEQ_LEN:\n",
    "        return seq + [vocab['<PAD>']] * (MAX_SEQ_LEN - len(seq))\n",
    "    else:\n",
    "        return seq[:MAX_SEQ_LEN]\n",
    "\n",
    "df['input_ids'] = df['input_ids'].apply(pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6170c119-c3e8-4e46-b3a9-caf966d6113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "df['label'] = label_enc.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf497b6-efa6-4e7c-a88b-b557f4b3594b",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a52c5c09-50d6-4b37-b815-4b4e1f01792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ce3c4d31-80cb-4dce-9b7f-0c4efc7a7d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor([x for x in X], dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9434c112-6127-42bf-b25f-1b0c746298d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df['input_ids'].tolist(), df['label'].tolist(), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3efbbc32-4af3-42ba-9201-20e79fd3da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(X_train, y_train)\n",
    "val_dataset = SentimentDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers = 4, pin_memory  = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc236179-471e-4d17-86fb-e7c70fd00aa9",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8bc8f-813c-40d2-9c85-0fb4cc7b049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        out = self.dropout(hidden[-1])\n",
    "        return self.fc(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
